{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e08ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976955bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3190ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# print(X_train.shape)\n",
    "print(X_train[0])\n",
    "# print(y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a5302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = keras.datasets.imdb.get_word_index()\n",
    "# print(index_dict)\n",
    "\n",
    "index_rev_dict = dict((i+3, w) for (w,i) in index_dict.items())\n",
    "index_rev_dict[0] = '<pad>'\n",
    "index_rev_dict[1] = '<sos>'\n",
    "index_rev_dict[2] = '<unk>'\n",
    "\n",
    "def decode_review (rev_dict, encoded_review):\n",
    "    return ' '.join(rev_dict[i] for i in encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1224145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and switchblade romance bursting on to the scene maléfique preceded the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made maléfique was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is complimented by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named carrère sent to prison for fraud he is put in a cell with three others the quietly insane lassalle body building transvestite marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old journal after translating part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that maléfique makes the best of it's assets as despite it's restraints the film never actually feels restrained and manages to flow well throughout director eric valette provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell ensures that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really frightens people and this film proves that as the director ensures that we can never really be sure of exactly what is round the corner and this helps to ensure that maléfique actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall maléfique is a truly great horror film and one of the best of the decade highly recommended viewing\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(index_rev_dict, X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f00d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_len = np.array([len(review) for review in X_train])\n",
    "# min_len = review_len.min()\n",
    "min_len = 7\n",
    "cut_review = []\n",
    "for review in X_train:\n",
    "    cut_review.append(review[:min_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff54aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973]\n",
      "(25000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(cut_review[0])\n",
    "# decode_review(index_rev_dict, cut_review[0])\n",
    "\n",
    "X_train_cut = np.array(cut_review)\n",
    "print(X_train_cut.shape)\n",
    "# X_train_cut = np.expand_dims(X_train_cut, -1)\n",
    "# print(X_train_cut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ef3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 7, 10)             885840    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 10)                210       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 886,061\n",
      "Trainable params: 886,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 9s 10ms/step - loss: 0.6566 - accuracy: 0.5606\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5280 - accuracy: 0.7170\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.4143 - accuracy: 0.7974\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.3414 - accuracy: 0.8348\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2975 - accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2729 - accuracy: 0.8690\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.2527 - accuracy: 0.8797\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2395 - accuracy: 0.8819\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2297 - accuracy: 0.8901\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.2219 - accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c79188550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "#     keras.layers.Embedding(len(index_dict), 10, input_length=11),\n",
    "    keras.layers.Embedding(len(index_dict), 10, input_length=7),\n",
    "    keras.layers.SimpleRNN(10),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(#loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "                loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer = 'adam', metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "model.fit(X_train_cut, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1151a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test.shape)\n",
    "#print(X_test[0])\n",
    "#x = []\n",
    "#for i in X_test:\n",
    "#    x.append(len(i))\n",
    "#x = np.array(x)\n",
    "#print(x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782e9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.0186 - accuracy: 0.5967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0185835361480713, 0.5967199802398682]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cut=[]\n",
    "for r in X_test:\n",
    "    X_test_cut.append(r[:7])\n",
    "    \n",
    "X_test_cut = np.array(X_test_cut)\n",
    "print(type(X_test_cut))\n",
    "model.evaluate(X_test_cut, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbeab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'like', 'cat'], ['You', 'like', 'apple'], ['I', 'hate', 'dog'], ['You', 'hate', 'peach']]\n",
      "{'I', 'cat', 'hate', 'peach', 'like', 'apple', 'dog', 'You'}\n",
      "{'I': 0, 'cat': 1, 'hate': 2, 'peach': 3, 'like': 4, 'apple': 5, 'dog': 6, 'You': 7}\n",
      "[[0, 4, 1], [7, 4, 5], [0, 2, 6], [7, 2, 3]]\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "\n",
    "txt = [\n",
    "    'I like cat',\n",
    "    'You like apple',\n",
    "    'I hate dog',\n",
    "    'You hate peach'\n",
    "]\n",
    "\n",
    "word_seq = []\n",
    "vocab = set()\n",
    "\n",
    "for t in txt:\n",
    "    y = t.split(sep=' ')\n",
    "    word_seq.append(y)\n",
    "    for y_i in y:\n",
    "        vocab.add(y_i)\n",
    "        \n",
    "print(word_seq)\n",
    "print(vocab)\n",
    "\n",
    "vocab_dict = dict(zip(vocab, np.arange(len(vocab))))\n",
    "print(vocab_dict)\n",
    "\n",
    "encoded_txt = []\n",
    "for x in word_seq:\n",
    "    encoded_seq = []\n",
    "    for y in x:\n",
    "        encoded_seq.append(vocab_dict[y])\n",
    "    encoded_txt.append(encoded_seq)\n",
    "    \n",
    "print(encoded_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e78cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "[[[-0.03946376  0.01375205  0.01850296 -0.03526982  0.03493699]\n",
      "  [ 0.00778514 -0.03199431  0.00979537 -0.02257398  0.03647676]\n",
      "  [ 0.01384829  0.04369333  0.0206232  -0.01066697 -0.0104901 ]]\n",
      "\n",
      " [[-0.02931552  0.02312768  0.02466953 -0.02837609  0.04720724]\n",
      "  [ 0.00778514 -0.03199431  0.00979537 -0.02257398  0.03647676]\n",
      "  [ 0.04931628 -0.04078038  0.03443583 -0.02169433  0.02348722]]\n",
      "\n",
      " [[-0.03946376  0.01375205  0.01850296 -0.03526982  0.03493699]\n",
      "  [ 0.02278748 -0.03825533 -0.04985806  0.00403781  0.04677291]\n",
      "  [ 0.04607267  0.03524548 -0.02088434 -0.0418024  -0.02910771]]\n",
      "\n",
      " [[-0.02931552  0.02312768  0.02466953 -0.02837609  0.04720724]\n",
      "  [ 0.02278748 -0.03825533 -0.04985806  0.00403781  0.04677291]\n",
      "  [ 0.04124716 -0.00378274 -0.04757272 -0.0004464  -0.03233638]]]\n"
     ]
    }
   ],
   "source": [
    "m1 = keras.Sequential([\n",
    "    keras.layers.Embedding(len(vocab), input_length=3, output_dim=5)\n",
    "])\n",
    "out = m1.predict(np.array(encoded_txt))\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
