{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43a29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3ea809",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EDA\n",
    "\n",
    "def df_check(df):\n",
    "    ret_df = pd.DataFrame()\n",
    "    feature_names=['missing count', 'u_count', 'min','max','mean', 'median', 'std']\n",
    "    i = 0\n",
    "    for s in df:\n",
    "        s_list = []\n",
    "        s_list.append(s)\n",
    "        #s_list.append((df[s].isna().sum()*100)/len(df[s]))\n",
    "        s_list.append(df[s].isna().sum())\n",
    "        s_list.append(len(df[s].unique()))\n",
    "        try:\n",
    "            df[s].astype('float64')\n",
    "            s_list.append(df[s].min())\n",
    "            s_list.append(df[s].max())\n",
    "            s_list.append(df[s].mean())\n",
    "            s_list.append(df[s].median())\n",
    "            s_list.append(df[s].std())\n",
    "        except:\n",
    "            for _ in range(5):\n",
    "                s_list.append(np.NaN)\n",
    "        finally:\n",
    "            ret_df.insert(i, s, pd.Series(s_list[1:]))\n",
    "            i = i+1\n",
    "    x = ret_df.T\n",
    "    x.columns = feature_names\n",
    "    return x\n",
    "\n",
    "### read raw data\n",
    "pd_train = pd.read_csv('train.csv')\n",
    "pd_test = pd.read_csv('test.csv')\n",
    "\n",
    "### check shape, features, basic statistics\n",
    "r = df_check(pd_train)\n",
    "#print(r)\n",
    "#print(df_check(pd_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25404c6",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "#### Train\n",
    "\n",
    "* 학습 타겟용 'Survived' -  feature / dimension / df column 있음.\n",
    "* 'Age' (177/891), 'Cabin' (687/891), 'Embarked' (2/891) 결측치.\n",
    "\n",
    "\n",
    "### Test\n",
    "* 'Age' (86/418), 'Cabin' (327/418), 'Fare (1/418)' 결측치.\n",
    "\n",
    "### 기타\n",
    "* 'Cabin', 'Name', 'Ticket' 사용않기로 함.\n",
    "\n",
    "\n",
    "### todo\n",
    "* outlier check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### missing value -- mean, median, 고빈도 값으로 대체\n",
    "\n",
    "### read raw data\n",
    "pd_train = pd.read_csv('train.csv')\n",
    "pd_test = pd.read_csv('test.csv')\n",
    "\n",
    "### align train, test dataframes\n",
    "y_train = pd_train['Survived'].values\n",
    "pd_train.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "g1 = pd_train.groupby(['Pclass', 'Sex'])\n",
    "g2 = pd_test.groupby(['Pclass', 'Sex'])\n",
    "\n",
    "### missing value: Age\n",
    "# mean, median(50%) 가까움, mean 값으로 대체\n",
    "#print(g1['Age'].describe())\n",
    "\n",
    "df_age_mean = pd.DataFrame()\n",
    "m1 = g1['Age'].mean()\n",
    "m2 = g2['Age'].mean()\n",
    "\n",
    "df_age_mean.insert(0, 'pd_train', m1)\n",
    "df_age_mean.insert(1, 'pd_test', m2)\n",
    "\n",
    "pd_data = pd.concat([pd_train, pd_test], ignore_index=True)\n",
    "g3 = pd_data.groupby(['Pclass', 'Sex'])\n",
    "m3 = g3['Age'].mean()\n",
    "df_age_mean.insert(2, 'pd_data', m3)\n",
    "\n",
    "#print(df_age_mean)\n",
    "\n",
    "f1 = pd_data['Age'].isna()\n",
    "f2 = pd_data['Age'].notna()\n",
    "#print(pd_data[f1])\n",
    "\n",
    "### missing value: Fare \n",
    "# mean, median(50%) 차이. outlier영향 있을것으로 예상. median 값으로 대체\n",
    "#print(g1['Fare'].describe())\n",
    "\n",
    "df_fare_desc = g1['Fare'].describe()\n",
    "\n",
    "### missing value: Embarked\n",
    "# 빈도수 높은 top 값으로 대체\n",
    "#print(g1['Embarked'].describe())\n",
    "\n",
    "df_embarked_desc = g1['Embarked'].describe()\n",
    "\n",
    "# drop unused features\n",
    "pd_data = pd_data.drop(['Name', 'Cabin', 'Ticket'], axis=1)\n",
    "\n",
    "def df_fill_missing(df):\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i, :]\n",
    "        row_pclass = row['Pclass']\n",
    "        row_sex = row['Sex']\n",
    "        row_fare = row['Fare']\n",
    "        \n",
    "        if np.isnan(row['Age']):\n",
    "            df.loc[i, 'Age'] = df_age_mean.loc[(row_pclass, row_sex), 'pd_data']\n",
    "            \n",
    "        if np.isnan(row['Fare']):\n",
    "            df.loc[i, 'Fare'] = df_fare_desc.loc[(row_pclass, row_sex), '50%']\n",
    "        \n",
    "        if row['Embarked'] is np.NaN:\n",
    "            df.loc[i, 'Embarked'] = df_embarked_desc.loc[(row_pclass, row_sex), 'top']\n",
    "\n",
    "def df_catvalue(df):\n",
    "    for s in df:\n",
    "        try:\n",
    "            df[s].astype('float64')\n",
    "        except:\n",
    "            if len(df[s].unique())<10:\n",
    "                df[s] = df[s].astype('category').cat.codes\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "df_fill_missing(pd_data)\n",
    "df_catvalue(pd_data)\n",
    "df_check(pd_data)\n",
    "#print(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_predict = pd.DataFrame()\n",
    "\n",
    "### missing value, age -- linear regression\n",
    "df_age_predict.insert(0, 'mean', pd_data[f1]['Age'])\n",
    "#print(pd_data[f2])\n",
    "#print(df_age_predict)\n",
    "\n",
    "age_x_train = pd_data[f2].drop('Age', axis=1)\n",
    "age_y_train = pd_data[f2].loc[:, 'Age']\n",
    "age_x_predict = pd_data[f1].drop('Age', axis=1)\n",
    "\n",
    "#print(age_x_predict)\n",
    "\n",
    "### scale\n",
    "def minmax(s):\n",
    "    return (s-s.min())/(s.max()-s.min())\n",
    "\n",
    "for dset in [age_x_train, age_x_predict]:\n",
    "    for c in dset.iloc[:, 1:]:\n",
    "        dset[c] = minmax(dset[c])\n",
    "        \n",
    "#print(age_y_train)\n",
    "\n",
    "lr = LinearRegression().fit(age_x_train, age_y_train)\n",
    "p = lr.predict(age_x_predict)\n",
    "\n",
    "df_age_predict.insert(1, 'lr_predict', pd.Series(p, index = df_age_predict.index))\n",
    "#print(df_age_predict)\n",
    "\n",
    "for i in df_age_predict.index:\n",
    "    pd_data.loc[i, 'Age'] = df_age_predict.loc[i, 'lr_predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### scale - minmax, exclude PassengerId\n",
    "\n",
    "def minmax(s):\n",
    "    return (s-s.min())/(s.max()-s.min())\n",
    "\n",
    "for c in pd_data.iloc[:, 1:]:\n",
    "    pd_data[c] = minmax(pd_data[c])\n",
    "#print(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d149ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split\n",
    "train_len = len(y_train)\n",
    "\n",
    "X_train = pd_data.iloc[:train_len, 1:]\n",
    "X_test = pd_data.iloc[train_len:, 1:]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape)\n",
    "#print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DNN\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(7, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = keras.losses.BinaryCrossentropy(),\n",
    "             optimizer = keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs = 50, verbose=0)\n",
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa628477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d54dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)\n",
    "\n",
    "p = rf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
